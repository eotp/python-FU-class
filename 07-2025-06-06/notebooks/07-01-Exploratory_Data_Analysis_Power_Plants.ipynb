{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installationsanweisungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "conda install -c conda-forge geopandas\n",
    "\n",
    "conda install -c conda-forge cartopy\n",
    "\n",
    "\n",
    "---------------------------------------\n",
    "## Win : pip install gdal\n",
    "\n",
    "## Mac : brew install gdal\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis in Action: global power plant distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subsequent notebooks we apply a variety of EDA techniques on a real world data set.\n",
    "\n",
    "The data set [__Global Power-Plants__](https://www.kaggle.com/ramjasmaurya/global-powerplants) is available on [Kaggle](https://www.kaggle.com/).\n",
    "\n",
    "\n",
    "\n",
    "It was already downloaded for you and is found in the `datasets` folder:\n",
    "\n",
    "    ../data/powerplants.csv\n",
    "\n",
    "<img src=\"./_img/power_plant.webp\"> \n",
    "\n",
    "Source: [The Quint](https://www.thequint.com/news/environment/thermal-power-plants-use-up-more-water-than-permitted-rti-data-shows/).\n",
    "\n",
    "### Content\n",
    "\n",
    "This dataset consists of information about power plants worldwide. Each record includes the name, country, energy source type, geographic location, start date and other data elements. In this data analysis we want to learn someting about the geospatial distribution and the energy share of power plants in the world and in specific regions. Referring to the global goals of reducing the greenhouse gas emissions the energy production sector is one of the most important one. Actual knowledge about the specific energy share of green / fossil energy source and its change in time is therefore an important information for political decissions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./_img/Time_data_science.png)\n",
    "\n",
    "Source: [Gil Press (2016)](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#55852a146f63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pd.read_csv(\"../data/powerplants.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34936, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country code</th>\n",
       "      <th>country</th>\n",
       "      <th>name of powerplant</th>\n",
       "      <th>capacity in MW</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>primary_fuel</th>\n",
       "      <th>secondary fuel</th>\n",
       "      <th>other_fuel 1</th>\n",
       "      <th>other_fuel 2</th>\n",
       "      <th>start date</th>\n",
       "      <th>owner of plant</th>\n",
       "      <th>geolocation_source</th>\n",
       "      <th>generation_gwh_2020</th>\n",
       "      <th>generation_data_source</th>\n",
       "      <th>estimated_generation_gwh_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20406</th>\n",
       "      <td>ESP</td>\n",
       "      <td>Spain</td>\n",
       "      <td>LA ROBLA GRUPO 2</td>\n",
       "      <td>619.06</td>\n",
       "      <td>42.7924</td>\n",
       "      <td>-5.6340</td>\n",
       "      <td>Coal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>GAS NATURAL FENOSA GENERACION  S.L.U.</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JRC-PPDB-OPEN</td>\n",
       "      <td>2823.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19357</th>\n",
       "      <td>RUS</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Iovskaya HPP</td>\n",
       "      <td>96.00</td>\n",
       "      <td>66.6692</td>\n",
       "      <td>31.3894</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>PJSC \"TGC-1\"</td>\n",
       "      <td>EnergyBase (RUS)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>CHN</td>\n",
       "      <td>China</td>\n",
       "      <td>Qingtongxia</td>\n",
       "      <td>272.00</td>\n",
       "      <td>37.8800</td>\n",
       "      <td>105.9900</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>925.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23661</th>\n",
       "      <td>GBR</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Metheringham Heath (Farm AD)</td>\n",
       "      <td>6.50</td>\n",
       "      <td>53.1334</td>\n",
       "      <td>-0.4721</td>\n",
       "      <td>Biomass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Future Biogas (Blankney Estate)</td>\n",
       "      <td>UK Renewable Energy Planning Database</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30764</th>\n",
       "      <td>USA</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North Adams Landfill</td>\n",
       "      <td>2.20</td>\n",
       "      <td>42.6691</td>\n",
       "      <td>-73.0920</td>\n",
       "      <td>Solar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Syncarpha North Adams  LLC</td>\n",
       "      <td>U.S. Energy Information Administration</td>\n",
       "      <td>3.537</td>\n",
       "      <td>U.S. Energy Information Administration</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>CHN</td>\n",
       "      <td>China</td>\n",
       "      <td>Liangfengke</td>\n",
       "      <td>52.00</td>\n",
       "      <td>32.8306</td>\n",
       "      <td>105.0764</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNFCCC CDM Registry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748</th>\n",
       "      <td>CHN</td>\n",
       "      <td>China</td>\n",
       "      <td>Putian Shijing</td>\n",
       "      <td>40.00</td>\n",
       "      <td>25.2102</td>\n",
       "      <td>119.2899</td>\n",
       "      <td>Wind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNFCCC CDM Registry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34902</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Tuyen Quang</td>\n",
       "      <td>342.00</td>\n",
       "      <td>22.3600</td>\n",
       "      <td>105.3985</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Vietnam Electricity (EVN)</td>\n",
       "      <td>Open Development Vietnam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Open Development Vietnam</td>\n",
       "      <td>1036.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24708</th>\n",
       "      <td>GBR</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Yorkley Solar Park</td>\n",
       "      <td>5.00</td>\n",
       "      <td>51.7459</td>\n",
       "      <td>-2.5356</td>\n",
       "      <td>Solar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bee Green Solar</td>\n",
       "      <td>UK Renewable Energy Planning Database</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182</th>\n",
       "      <td>CHN</td>\n",
       "      <td>China</td>\n",
       "      <td>Jiulitancun A</td>\n",
       "      <td>5.00</td>\n",
       "      <td>37.6170</td>\n",
       "      <td>108.9260</td>\n",
       "      <td>Solar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wiki-Solar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country code                   country            name of powerplant  \\\n",
       "20406          ESP                     Spain              LA ROBLA GRUPO 2   \n",
       "19357          RUS                    Russia                  Iovskaya HPP   \n",
       "7833           CHN                     China                   Qingtongxia   \n",
       "23661          GBR            United Kingdom  Metheringham Heath (Farm AD)   \n",
       "30764          USA  United States of America          North Adams Landfill   \n",
       "7299           CHN                     China                   Liangfengke   \n",
       "7748           CHN                     China                Putian Shijing   \n",
       "34902          VNM                   Vietnam                   Tuyen Quang   \n",
       "24708          GBR            United Kingdom            Yorkley Solar Park   \n",
       "7182           CHN                     China                 Jiulitancun A   \n",
       "\n",
       "       capacity in MW  latitude  longitude primary_fuel secondary fuel  \\\n",
       "20406          619.06   42.7924    -5.6340         Coal            NaN   \n",
       "19357           96.00   66.6692    31.3894        Hydro            NaN   \n",
       "7833           272.00   37.8800   105.9900        Hydro            NaN   \n",
       "23661            6.50   53.1334    -0.4721      Biomass            NaN   \n",
       "30764            2.20   42.6691   -73.0920        Solar            NaN   \n",
       "7299            52.00   32.8306   105.0764        Hydro            NaN   \n",
       "7748            40.00   25.2102   119.2899         Wind            NaN   \n",
       "34902          342.00   22.3600   105.3985        Hydro            NaN   \n",
       "24708            5.00   51.7459    -2.5356        Solar            NaN   \n",
       "7182             5.00   37.6170   108.9260        Solar            NaN   \n",
       "\n",
       "      other_fuel 1 other_fuel 2  start date  \\\n",
       "20406          NaN          NaN      1984.0   \n",
       "19357          NaN          NaN      1960.0   \n",
       "7833           NaN          NaN      1978.0   \n",
       "23661          NaN          NaN         NaN   \n",
       "30764          NaN          NaN      2015.0   \n",
       "7299           NaN          NaN         NaN   \n",
       "7748           NaN          NaN         NaN   \n",
       "34902          NaN          NaN      2008.0   \n",
       "24708          NaN          NaN         NaN   \n",
       "7182           NaN          NaN         NaN   \n",
       "\n",
       "                              owner of plant  \\\n",
       "20406  GAS NATURAL FENOSA GENERACION  S.L.U.   \n",
       "19357                           PJSC \"TGC-1\"   \n",
       "7833                                     NaN   \n",
       "23661        Future Biogas (Blankney Estate)   \n",
       "30764             Syncarpha North Adams  LLC   \n",
       "7299                                     NaN   \n",
       "7748                                     NaN   \n",
       "34902              Vietnam Electricity (EVN)   \n",
       "24708                        Bee Green Solar   \n",
       "7182                                     NaN   \n",
       "\n",
       "                           geolocation_source  generation_gwh_2020  \\\n",
       "20406                                   GEODB                  NaN   \n",
       "19357                        EnergyBase (RUS)                  NaN   \n",
       "7833                                      NaN                  NaN   \n",
       "23661   UK Renewable Energy Planning Database                  NaN   \n",
       "30764  U.S. Energy Information Administration                3.537   \n",
       "7299                      UNFCCC CDM Registry                  NaN   \n",
       "7748                      UNFCCC CDM Registry                  NaN   \n",
       "34902                Open Development Vietnam                  NaN   \n",
       "24708   UK Renewable Energy Planning Database                  NaN   \n",
       "7182                               Wiki-Solar                  NaN   \n",
       "\n",
       "                       generation_data_source  estimated_generation_gwh_2020  \n",
       "20406                           JRC-PPDB-OPEN                        2823.98  \n",
       "19357                                     NaN                         321.58  \n",
       "7833                                      NaN                         925.54  \n",
       "23661                                     NaN                            NaN  \n",
       "30764  U.S. Energy Information Administration                           2.71  \n",
       "7299                                      NaN                         201.80  \n",
       "7748                                      NaN                          74.22  \n",
       "34902                Open Development Vietnam                        1036.37  \n",
       "24708                                     NaN                           7.61  \n",
       "7182                                      NaN                           8.43  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "[Data cleansing or data cleaning](https://en.wikipedia.org/wiki/Data_cleansing) is the process of **detecting and correcting (or removing) corrupt or inaccurate records** from a record set, table, or database and refers to **identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with incomplete (`NaN`) and irrelevant data\n",
    "\n",
    "Missing values in data sets are a well-known problem as nearly everywhere, where data is measured and recorded, issues with missing values occur. Various reasons lead to missing values: values may not be measured, values may be measured but get lost or values may be measured but are considered unusable. Missing values can lead to problems, because often further data processing and analysis steps rely on complete data sets. Therefore missing values need to be replaced with reasonable values. In statistics this process is called **imputation**.\n",
    "\n",
    "When faced with the problem of missing values it is important to understand the mechanism that causes missing data. Such an understanding is useful, as it may be employed as background knowledge for selecting an appropriate imputation strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for `NaN`**\n",
    "\n",
    "Note that in many cases missing values are assigned special characters, such as `-999`, `NA`, `k.A.` etc.; hence, you as a data analyst are responsible for taking appropriate action.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34936"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country code                     34936\n",
       "country                          34936\n",
       "name of powerplant               34936\n",
       "capacity in MW                   34936\n",
       "latitude                         34936\n",
       "longitude                        34936\n",
       "primary_fuel                     34936\n",
       "secondary fuel                    1944\n",
       "other_fuel 1                       276\n",
       "other_fuel 2                        92\n",
       "start date                       17447\n",
       "owner of plant                   20868\n",
       "geolocation_source               34517\n",
       "generation_gwh_2020               9659\n",
       "generation_data_source           11400\n",
       "estimated_generation_gwh_2020    33138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country code                         0\n",
       "country                              0\n",
       "name of powerplant                   0\n",
       "capacity in MW                       0\n",
       "latitude                             0\n",
       "longitude                            0\n",
       "primary_fuel                         0\n",
       "secondary fuel                   32992\n",
       "other_fuel 1                     34660\n",
       "other_fuel 2                     34844\n",
       "start date                       17489\n",
       "owner of plant                   14068\n",
       "geolocation_source                 419\n",
       "generation_gwh_2020              25277\n",
       "generation_data_source           23536\n",
       "estimated_generation_gwh_2020     1798\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Challenge:** Calculate the percentage of NaN-values in each column. (4 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/percentage.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategies to deal with missing data in Python**\n",
    "\n",
    "In general there are many options to consider when imputing missing values, for example:\n",
    "* A constant value that has meaning within the domain, such as 0, distinct from all other values.\n",
    "* A value from another randomly selected record.\n",
    "* A mean, median or mode value for the column.\n",
    "* A value estimated by another predictive model.\n",
    "\n",
    "There are some libraries implementing more or less advanced missing value imputation strategies such as \n",
    "\n",
    "* [`statsmodels`](http://www.statsmodels.org/dev/imputation.html) ([Multiple Imputation with Chained Equations (MICE)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/))\n",
    "* [`fancyimpute`](https://github.com/iskandr/fancyimpute) (matrix completion and imputation algorithms)\n",
    "* [`scikit-learn`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html) (mean, median, most frequent)\n",
    "* [`pandas`](https://pandas.pydata.org/pandas-docs/stable/missing_data.html) ([`fillna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html), [`interpolate`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html) methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our working strategy to deal with missing data**\n",
    "\n",
    "_Owing to the fact that the amount of missing values in our data set is considerable high and that we can not easily do predictions or assumptions for the specific missing values, we simply remove these columns with a high amount of missing data._ \n",
    "\n",
    "_Nethertheless we have to keep in mind that our dataset still consists of gaps. Therefore we have to handle these gaps individually in the following analysis._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Challenge:** Drop all columns in the dataframe that have more than 60 percent null values. Refactor your code afterwards and externalise your code into a function that takes the original dataframe and a threshold. The function should return the new dataframe.\n",
    "\n",
    "> **Hint**: Make use of the `df.index` attribute. (8 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country code                      0.00\n",
       "country                           0.00\n",
       "name of powerplant                0.00\n",
       "capacity in MW                    0.00\n",
       "latitude                          0.00\n",
       "longitude                         0.00\n",
       "primary_fuel                      0.00\n",
       "secondary fuel                   94.44\n",
       "other_fuel 1                     99.21\n",
       "other_fuel 2                     99.74\n",
       "start date                       50.06\n",
       "owner of plant                   40.27\n",
       "geolocation_source                1.20\n",
       "generation_gwh_2020              72.35\n",
       "generation_data_source           67.37\n",
       "estimated_generation_gwh_2020     5.15\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with a ratio of 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['country code', 'country', 'name of powerplant', 'capacity in MW',\n",
       "       'latitude', 'longitude', 'primary_fuel'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hint: The index attribute allows us to extract the column names in this case\n",
    "ratios = ((pp.isnull().sum() / pp.shape[0]) * 100).round(2)\n",
    "display(ratios)\n",
    "# for example here are the columns for which the \"missing-ness\" ratio is 0\n",
    "print() # new line\n",
    "print(\"Columns with a ratio of 0\")\n",
    "display(ratios.loc[ratios == 0.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* Remember the `copy()` method to return the result of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/filter_dataframe.py\n",
    "def filter_dataframe(df, threshold):\n",
    "    # build pandas Series containing column name as index and ratio as value\n",
    "    ratios = ((df.isnull().sum() / df.shape[0]) * 100).round(2)\n",
    "    # get column names (index) for which ratio is under threshold\n",
    "    columns_to_keep = ratios.loc[ratios <= threshold].index\n",
    "    # get column names (index) for which ratio is over threshold\n",
    "    columns_to_drop = ratios.loc[ratios > threshold].index\n",
    "    # print dropped columns just to give info\n",
    "    print(f\"Dropped columns: {list(columns_to_drop)}\")\n",
    "    # return DataFrame only containing desired columns\n",
    "    return df[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns before cleanup: 16\n",
      "Dropped columns: ['secondary fuel', 'other_fuel 1', 'other_fuel 2', 'generation_gwh_2020', 'generation_data_source']\n",
      "Number of columns after cleanup: 11\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of columns before cleanup: {pp.shape[1]}\")\n",
    "pp = filter_dataframe(pp, threshold=60)\n",
    "print(f\"Number of columns after cleanup: {pp.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dealing with data structures\n",
    "\n",
    "Upon closer inspection we see that the `start date` column is stored as a floating point number only containing a year (which is rather an integer, isn't it?).\n",
    "\n",
    "For simplicity let's transform it to integer numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country code</th>\n",
       "      <th>start date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>BRA</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31075</th>\n",
       "      <td>USA</td>\n",
       "      <td>1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16815</th>\n",
       "      <td>JPN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12538</th>\n",
       "      <td>DEU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>BRA</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575</th>\n",
       "      <td>IND</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>GBR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24459</th>\n",
       "      <td>GBR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>CHN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18494</th>\n",
       "      <td>POL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country code  start date\n",
       "3248           BRA      2013.0\n",
       "31075          USA      1986.0\n",
       "16815          JPN         NaN\n",
       "12538          DEU         NaN\n",
       "3219           BRA      2008.0\n",
       "15575          IND      1999.0\n",
       "23999          GBR         NaN\n",
       "24459          GBR         NaN\n",
       "7275           CHN         NaN\n",
       "18494          POL         NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp[[\"country code\", \"start date\"]].sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp['start date'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to transform the column to a integer datatype we have to deal with the `NaN` values.\n",
    "\n",
    "For example by assigning a distinct value that can't be achieved inside the column itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Challenge:** Assign an integer to NaN values using the `fillna()` and change the data type to integer using the `astype()` method. (5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/imputation.py\n",
    "pp[\"start date\"] = pp[\"start date\"].fillna(-1)\n",
    "pp[\"start date\"] = pp[\"start date\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country code</th>\n",
       "      <th>start date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>BRA</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31075</th>\n",
       "      <td>USA</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16815</th>\n",
       "      <td>JPN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12538</th>\n",
       "      <td>DEU</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>BRA</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575</th>\n",
       "      <td>IND</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>GBR</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24459</th>\n",
       "      <td>GBR</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>CHN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18494</th>\n",
       "      <td>POL</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country code  start date\n",
       "3248           BRA        2013\n",
       "31075          USA        1986\n",
       "16815          JPN          -1\n",
       "12538          DEU          -1\n",
       "3219           BRA        2008\n",
       "15575          IND        1999\n",
       "23999          GBR          -1\n",
       "24459          GBR          -1\n",
       "7275           CHN          -1\n",
       "18494          POL          -1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp[[\"country code\", \"start date\"]].sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of spatial datasets\n",
    "\n",
    "_Note: In the subsequent cells we load Python library for spatial data analysis, such as `shapely`, `fiona`, `geopandas`, `cartopy` and `folium`. Make sure that you have installed the [GDAL bindings](http://www.gdal.org/index.html) on your computer._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we make use third party libraries for visualisation of the geospatial information, such as [GeoPandas](http://geopandas.org/index.html) and [shapely](http://toblerity.org/shapely/), which abstract away many algorithmic or computational issues related to spatial data processing and plotting by integrating the workhorses of geospatial computing, such as [GEOS](http://trac.osgeo.org/geos/), [GDAL](http://www.gdal.org/), [OGR](http://gdal.org/1.11/ogr/) and [proj.4](http://proj4.org/), among others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geographical information is stored and given by the `latitude` and `longitude` column. We can use these information to localize each power plant in the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform the variables `Target Latitude` and `Target Longitude` to spatial coordinates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<POINT (65.119 32.322)>,\n",
       " <POINT (65.795 31.67)>,\n",
       " <POINT (65.792 31.623)>,\n",
       " <POINT (69.479 34.556)>,\n",
       " <POINT (69.717 34.641)>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapely.geometry import Point\n",
    "geometry = [Point(xy) for xy in zip(pp['longitude'], pp['latitude'])]\n",
    "geometry[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Point` class does not yield any useful information upon printing it. \n",
    "\n",
    "However it contains `x` and `y` attributes that map our longitudes and latitudes onto x-y coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.119\n",
      "32.322\n"
     ]
    }
   ],
   "source": [
    "point_0 = geometry[0]\n",
    "print(point_0.x)\n",
    "print(point_0.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is nothing more than a slightly more efficient way of storing coordinates. \n",
    "\n",
    "And the library that will allow us to describe coordinates uses exactly this representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the GeoPandas to make a pandas `DataFrame` spatially aware.**\n",
    "\n",
    "[GeoPandas](http://geopandas.org/index.html) extends the datatypes used by pandas to allow spatial operations on geometric types. Geometric operations are performed by [shapely](https://shapely.readthedocs.io/en/stable/). GeoPandas further depends on [fiona](https://fiona.readthedocs.io/en/stable/) for file access and descartes and [matplotlib](https://matplotlib.org/) for plotting.\n",
    "\n",
    "It combines the capabilities of pandas and shapely, providing geospatial operations in pandas and a high-level interface to multiple geometries to shapely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zak\\anaconda3\\envs\\fupy5\\lib\\site-packages\\pyproj\\network.py:59: UserWarning: pyproj unable to set PROJ database path.\n",
      "  _set_context_ca_bundle_path(ca_bundle_path)\n",
      "Cannot find header.dxf (GDAL_DATA is not defined)\n",
      "PROJ: proj_create_from_database: SQLite error on SELECT key, value FROM metadata WHERE key IN ('DATABASE.LAYOUT.VERSION.MAJOR', 'DATABASE.LAYOUT.VERSION.MINOR'): no such table: metadata\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country code</th>\n",
       "      <th>country</th>\n",
       "      <th>name of powerplant</th>\n",
       "      <th>capacity in MW</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>primary_fuel</th>\n",
       "      <th>start date</th>\n",
       "      <th>owner of plant</th>\n",
       "      <th>geolocation_source</th>\n",
       "      <th>estimated_generation_gwh_2020</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kajaki Hydroelectric Power Plant Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.322</td>\n",
       "      <td>65.1190</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>119.50</td>\n",
       "      <td>POINT (65.11900 32.32200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kandahar DOG</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.670</td>\n",
       "      <td>65.7950</td>\n",
       "      <td>Solar</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wiki-Solar</td>\n",
       "      <td>18.29</td>\n",
       "      <td>POINT (65.79500 31.67000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kandahar JOL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.623</td>\n",
       "      <td>65.7920</td>\n",
       "      <td>Solar</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wiki-Solar</td>\n",
       "      <td>18.72</td>\n",
       "      <td>POINT (65.79200 31.62300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Mahipar Hydroelectric Power Plant Afghanistan</td>\n",
       "      <td>66.0</td>\n",
       "      <td>34.556</td>\n",
       "      <td>69.4787</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>174.91</td>\n",
       "      <td>POINT (69.47870 34.55600)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Naghlu Dam Hydroelectric Power Plant Afghanistan</td>\n",
       "      <td>100.0</td>\n",
       "      <td>34.641</td>\n",
       "      <td>69.7170</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>350.80</td>\n",
       "      <td>POINT (69.71700 34.64100)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country code      country                                name of powerplant  \\\n",
       "0          AFG  Afghanistan      Kajaki Hydroelectric Power Plant Afghanistan   \n",
       "1          AFG  Afghanistan                                      Kandahar DOG   \n",
       "2          AFG  Afghanistan                                      Kandahar JOL   \n",
       "3          AFG  Afghanistan     Mahipar Hydroelectric Power Plant Afghanistan   \n",
       "4          AFG  Afghanistan  Naghlu Dam Hydroelectric Power Plant Afghanistan   \n",
       "\n",
       "   capacity in MW  latitude  longitude primary_fuel  start date  \\\n",
       "0            33.0    32.322    65.1190        Hydro          -1   \n",
       "1            10.0    31.670    65.7950        Solar          -1   \n",
       "2            10.0    31.623    65.7920        Solar          -1   \n",
       "3            66.0    34.556    69.4787        Hydro          -1   \n",
       "4           100.0    34.641    69.7170        Hydro          -1   \n",
       "\n",
       "  owner of plant geolocation_source  estimated_generation_gwh_2020  \\\n",
       "0            NaN              GEODB                         119.50   \n",
       "1            NaN         Wiki-Solar                          18.29   \n",
       "2            NaN         Wiki-Solar                          18.72   \n",
       "3            NaN              GEODB                         174.91   \n",
       "4            NaN              GEODB                         350.80   \n",
       "\n",
       "                    geometry  \n",
       "0  POINT (65.11900 32.32200)  \n",
       "1  POINT (65.79500 31.67000)  \n",
       "2  POINT (65.79200 31.62300)  \n",
       "3  POINT (69.47870 34.55600)  \n",
       "4  POINT (69.71700 34.64100)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "gdf = gpd.GeoDataFrame(pp, geometry=geometry)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure that for every entry we have a valid spatial coordinates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Challenge:** Check the columns `longitude` and `latitude` for NaN-values. (4 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/long_lat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assign a spatial coordinate reference system (`crs`) to our GeoPandas object**\n",
    "\n",
    "In general the CRS may be defined in several ways, for example the CRS may be defined as [Well-known text (WKT)](https://en.wikipedia.org/wiki/Well-known_text) format, or [JSON](https://en.wikipedia.org/wiki/JSON) format, or [GML](https://en.wikipedia.org/wiki/Geography_Markup_Language) format, or in the [Proj4](https://en.wikipedia.org/wiki/PROJ.4) format, among many others.\n",
    "\n",
    "The Proj4 format is a generic, string-based description of a CRS. It defines projection types and parameter values for particular projections. For instance the Proj4 format string for the [European Terrestrial Reference System 1989 (ETRS89)](https://en.wikipedia.org/wiki/European_Terrestrial_Reference_System_1989) is:\n",
    "\n",
    "    +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no\\_defs\n",
    "\n",
    "With respect to the enormous amount of existing CRS the [International Association of Oil & Gas Producers (IOGP)](https://en.wikipedia.org/wiki/International_Association_of_Oil_%26_Gas_Producers), formerly known as **_European Petroleum Survey Group (EPSG)_**, built a collection of definitions for global, regional, national and local coordinate reference systems and coordinate transformations, the [EPSG Geodetic Parameter Dataset](http://www.epsg.org/). Within this collection each particular coordinate reference systems gets an unique integer identifier, commonly denoted as EPSG. For instance, the EPSG identifier for the the latest revision of the [World Geodetic System (WGS84)](https://en.wikipedia.org/wiki/World_Geodetic_System) is simply [4326](http://spatialreference.org/ref/epsg/4326/).\n",
    "\n",
    "\n",
    "A nice look up page for different coordinate reference systems is found [here](https://epsg.io/) and a fancy visualization of many prominent map projections is found [here](https://bl.ocks.org/mbostock/raw/3711652/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.set_crs('epsg:4326', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context matters: Load _Natural Earth countries_ dataset, bundled with GeoPandas\n",
    "\n",
    "[Natural Earth](http://www.naturalearthdata.com/) is a public domain map dataset available at 1:10m, 1:50m, and 1:110 million scales. Featuring tightly integrated vector and raster data, with Natural Earth you can make a variety of visually pleasing, well-crafted maps with cartography or GIS software. A subset comes bundled with GeoPandas and is accessible from the `gpd.datasets` module. We’ll use it as a helpful global base layer map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.plot(facecolor='lightgray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine world map and the power plant data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = world.plot(facecolor='lightgray') # create base plot (world map)\n",
    "gdf.plot(\n",
    "    ax=base,         # specify object to plot over\n",
    "    marker='o',      # select shape of each plotted point (circle, cross, etc.)\n",
    "    color='red',     # color\n",
    "    markersize=2,    # size of each plotted point\n",
    "    alpha=0.1        # transparency of each plotted point (areas with less powerplants will become less visible)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Spatial Filtering the data by geolocation\n",
    "\n",
    "In a world view the points observations overlap each over a lot. So we can not see any pattern. For those purpose it is usefull, to set the focus of the research to a specific geographical region. In the following we want to focus on a continental and a country view.\n",
    "\n",
    "**Europe focus**\n",
    "\n",
    "As a first example we want to restrict our analysis to data points, which refer to an area within Europe. Although it is not straightforward to define Europe as an entity, in terms of geography, politics or sphere of cultural identity, we define Europe as an area between the coordinates  \n",
    "\n",
    "$$\\text{33.0 to 73.5°N and 27.0°W to 45.0°E.}$$\n",
    "\n",
    "In order to represent that area spatially; we construct a `Polygon` object to represent the [bounding box](https://en.wikipedia.org/wiki/Minimum_bounding_box) of Europe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "# generate geopandas object\n",
    "poly_europe = gpd.GeoSeries([Polygon([(-27,33), (45,33), (45,73.5), (-27,73.5)])])\n",
    "bb_europe = gpd.GeoDataFrame({'geometry': poly_europe})\n",
    "# assign crs\n",
    "bb_europe.set_crs(epsg=4326, inplace=True)\n",
    "bb_europe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot world map and bounding box of Europe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = world.plot(facecolor='lightgray')\n",
    "bb_europe.plot(ax=base, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subset (intersect) the GeoPandas `DataFrame` with the bounding box of Europe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_europe = gpd.sjoin(gdf, bb_europe, how=\"inner\", predicate='intersects').drop(\"index_right\", axis=1)\n",
    "\n",
    "print(gdf_europe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_europe.plot(markersize=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We catch a bit of the African and Asian continent**\n",
    "\n",
    "Fortunately the Naturalearth dataset also contains continent definitions. We can again subset these together to take the intersection of both definitions of Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_europe = gpd.overlay(gdf_europe, world.loc[world['continent'] == 'Europe'], how='intersection')\n",
    "print(gdf_europe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_europe.plot(markersize=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result again is not perfect as we don't include the european part of Turkey for example.\n",
    "However the Naturalearth dataset alone also counts Russia and some islands far away from the European continent as Europe.\n",
    "\n",
    "This definition of Europe should be sufficient for our analysis. Although feel free to bring in your own if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.loc[world['continent'] == 'Europe'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to keep the spatial context we extract the area of Europe from the world map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europe = gpd.overlay(world, bb_europe, how='intersection')\n",
    "europe.set_crs('epsg:4326', inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = europe.plot(facecolor='lightgray')\n",
    "gdf_europe.plot(ax=base, marker='o', markersize=2, alpha=0.75);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with categorical data\n",
    "\n",
    "`geopandas` includes `column`, `categorical` and `legend` keywords in order to better distinguish between individual types of data inside the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = europe.plot(facecolor='lightgray')\n",
    "gdf_europe.plot(ax=base, marker='o', markersize=2, alpha=0.75, column='primary_fuel', categorical=True, legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing individual sub-categories\n",
    "\n",
    "As our dataset provides many categories the resulting plot is not necessarily ideal.\n",
    "\n",
    "Way too many categories are displayed and some even share the same color.\n",
    "\n",
    "One way to circumvent this is to chose individual categories we want to display.\n",
    "For example only the most prominent in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_europe[\"primary_fuel\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get top-5 categories\n",
    "gdf_europe[\"primary_fuel\"].value_counts().iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_fuels = gdf_europe[\"primary_fuel\"].value_counts().iloc[:5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_fuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = europe.plot(facecolor='lightgray')\n",
    "gdf_europe.loc[gdf_europe[\"primary_fuel\"].isin(top_5_fuels)].plot(\n",
    "        ax=base,                # plotting object to plot over\n",
    "        marker='o',             # marker shape\n",
    "        markersize=2,           # marker size\n",
    "        alpha=0.75,             # transparency\n",
    "        column='primary_fuel',  # column to pick categories from\n",
    "        categorical=True,       # force the plot to chose different colors for individual categories\n",
    "        legend=True             # include legend\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colors this way are selected by GeoPandas and may be unfitting. For better control we can loop over each fuel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary containing colors for each top_5 fuel kind\n",
    "colors = {\n",
    "    \"Solar\": \"yellow\",\n",
    "    \"Wind\": \"blue\",\n",
    "    \"Hydro\": \"aqua\",\n",
    "    \"Gas\": \"red\",\n",
    "    \"Biomass\": \"darkgoldenrod\",\n",
    "}\n",
    "\n",
    "# Plot base map\n",
    "base = europe.plot(facecolor='lightgray')\n",
    "for fuel in top_5_fuels:\n",
    "    # Plot each respective fuel\n",
    "    gdf_europe.loc[gdf_europe[\"primary_fuel\"] == fuel].plot(\n",
    "        ax=base,                # plotting object to plot over\n",
    "        marker='o',             # marker shape\n",
    "        markersize=2,           # marker size\n",
    "        alpha=0.5,              # transparency\n",
    "        color = colors[fuel],   # color\n",
    "        label = fuel            # name in legend\n",
    ")           \n",
    "base.legend() # show legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Still pretty ugly although more informative than the original plot**\n",
    "\n",
    "For further analysis let's add a new column which decides whether the fuel type is \"green\", i.e. sustainable, or not.\n",
    "\n",
    "**Feel free to add further categories or change the definition of sustainable energy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['primary_fuel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_fuels = ['Hydro', 'Solar', 'Wind', 'Biomass', 'Wave and Tidal', 'Geothermal']\n",
    "def is_green(entry):\n",
    "    return entry in green_fuels\n",
    "\n",
    "gdf['green'] = gdf['primary_fuel'].apply(is_green)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Challenge:** Try to select only entries within `green_fuels` using the `loc` and `isin()` method. (5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/locisin.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = world.plot(facecolor='lightgray')\n",
    "\n",
    "gdf.loc[gdf['green'] == True].plot(ax = base, markersize=2, alpha=0.1, color='green', label='green')\n",
    "gdf.loc[gdf['green'] == False].plot(ax = base, markersize=2, alpha=0.1, color='red', label='unsustainable')\n",
    "base.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The legend directly infers the marker shape, label and color from the plot. Since the low alpha we can barely see the corresponding markers.**\n",
    "> Hack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = world.plot(facecolor='lightgray')\n",
    "\n",
    "# Add dummy plots (of empty lists -> nothing to be plotted) for correct legend assignment\n",
    "base.scatter([],[],color='green', marker='o', label='green')\n",
    "base.scatter([],[],color='red', marker='o', label='unsustainable')\n",
    "\n",
    "gdf.loc[gdf['green'] == True].plot(ax = base, markersize=2, alpha=0.1, color='green')\n",
    "gdf.loc[gdf['green'] == False].plot(ax = base, markersize=2, alpha=0.1, color='red')\n",
    "base.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regional focus - Germany**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = world[world.name == \"Germany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_germany = gdf.loc[gdf['country'] == \"Germany\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germany = gpd.overlay(world, filtered, how='intersection')\n",
    "germany.set_crs('epsg:4326', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = germany.plot(facecolor='lightgray')\n",
    "# Add dummy plots (of empty lists -> nothing to be plotted) for correct legend assignment\n",
    "base.scatter([],[],color='green', marker='o', label='green')\n",
    "base.scatter([],[],color='red', marker='o', label='unsustainable')\n",
    "\n",
    "gdf_germany.loc[gdf_germany['green'] == True].plot(ax = base, markersize=4, alpha=0.7, color='green')\n",
    "gdf_germany.loc[gdf_germany['green'] == False].plot(ax = base, markersize=4, alpha=0.7, color='red')\n",
    "base.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable size of plotted points\n",
    "\n",
    "We can also add a column name as `markersize` argument inside the plotting method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = germany.plot(facecolor='lightgray')\n",
    "# Add dummy plots (of empty lists -> nothing to be plotted) for correct legend assignment\n",
    "base.scatter([],[],color='green', marker='o', label='green')\n",
    "base.scatter([],[],color='red', marker='o', label='unsustainable')\n",
    "\n",
    "gdf_germany.loc[gdf_germany['green'] == True].plot(ax = base, markersize=\"estimated_generation_gwh_2020\", alpha=0.7, color='green')\n",
    "gdf_germany.loc[gdf_germany['green'] == False].plot(ax = base, markersize=\"estimated_generation_gwh_2020\", alpha=0.7, color='red')\n",
    "base.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing the values**\n",
    "\n",
    "The resulting values are way too big. Before we have set `markersize = 4` and now the values of the column are taken which can be far greater than that.\n",
    "\n",
    "One way to deal with that, is to scale the data beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.g. Scale data to a set upper bound $m \\cdot \\frac{x}{max(x)}$**\n",
    "\n",
    "The maximum value in $x$ will now be equal to $m$ and all other values will keep the same relative distance to it.\n",
    "\n",
    "This may result in many very small points depending on the distribution of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = 400\n",
    "gdf_germany['estimated_generation_gwh_2020_scaled'] = upper_bound * gdf_germany['estimated_generation_gwh_2020'] / gdf_germany['estimated_generation_gwh_2020'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_germany['estimated_generation_gwh_2020_scaled'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = germany.plot(facecolor='lightgray')\n",
    "# Add dummy plots (of empty lists -> nothing to be plotted) for correct legend assignment\n",
    "base.scatter([],[],color='green', marker='o', label='green')\n",
    "base.scatter([],[],color='red', marker='o', label='unsustainable')\n",
    "\n",
    "gdf_germany.loc[gdf_germany['green'] == True].plot(ax = base, markersize=\"estimated_generation_gwh_2020_scaled\", alpha=0.7, color='green')\n",
    "gdf_germany.loc[gdf_germany['green'] == False].plot(ax = base, markersize=\"estimated_generation_gwh_2020_scaled\", alpha=0.7, color='red')\n",
    "base.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.g. Min-Max Scaling between $[a,b]$: $a + \\frac{(x-min(x)) \\cdot (b - a)}{max(x) - min(x)}$**\n",
    "\n",
    "This way we can control both the minimum and maximum values in which our values will end up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Challenge:** Try to calculate Min-Max Scaling for the column `gdf_germany['estimated_generation_gwh_2020']` with `a=4` and `b=400`. (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/minmax_manually.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the function `minmax_scaler()` from the `helper` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import minmax_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_germany['estimated_generation_gwh_2020_scaled'] = minmax_scaler(gdf_germany['estimated_generation_gwh_2020'], lower_bound=4, upper_bound=400)\n",
    "gdf_germany['estimated_generation_gwh_2020_scaled'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = germany.plot(facecolor='lightgray')\n",
    "# Add dummy plots (of empty lists -> nothing to be plotted) for correct legend assignment\n",
    "base.scatter([],[],color='green', marker='o', label='green')\n",
    "base.scatter([],[],color='red', marker='o', label='unsustainable')\n",
    "\n",
    "gdf_germany.loc[gdf_germany['green'] == True].plot(ax = base, markersize=\"estimated_generation_gwh_2020_scaled\", alpha=0.7, color='green')\n",
    "gdf_germany.loc[gdf_germany['green'] == False].plot(ax = base, markersize=\"estimated_generation_gwh_2020_scaled\", alpha=0.7, color='red')\n",
    "base.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the \"big\" dots stayed somewhat similar whereas the smaller ones grew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more colorful plots\n",
    "\n",
    "We offer a function to produce plots using earth projections you may be more familiar with.\n",
    "\n",
    "Feel free to take a look at it, the source file can be found in `src/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import cuteplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?cuteplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuteplot(gdf_europe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuteplot(gdf_europe.loc[gdf_europe[\"primary_fuel\"] == \"Solar\"], color = \"blue\", alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuteplot(gdf_europe.loc[gdf_europe[\"primary_fuel\"] == \"Solar\"], color = \"blue\", alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function returns a `Figure` and `Axes` object. Allowing for further manipulation. For example setting a title as shown here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = cuteplot(gdf.loc[gdf[\"primary_fuel\"] == \"Hydro\"], color = \"blue\", alpha = 0.3, map_extent=None, label = \"Solar\")\n",
    "\n",
    "ax.set_title(\"Hydro Power Plants across the Earth\", size=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also pass the ax object back inside and plot further points on top**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuteplot(gdf.loc[gdf[\"primary_fuel\"] == \"Coal\"], color = \"red\", alpha = 0.3, map_extent=None, label = \"Coal\", ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.legend(fontsize=16)\n",
    "ax.set_title(\"Hydro and Coal Powerplants across the earth\", size=24)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Saving our Dataframe to disk for further analysis\n",
    "\n",
    "We spend quite a lot of time for prepating our dataset for our analysis. At the end we want to save our dataframe to disk so that we can load this work state at every time again. There exist plenty of options, in this tutorial we want to use the `pickle` library to serialize our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_world = gpd.overlay(gdf, world, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_world = gdf_world[['country code', 'country', 'name of powerplant', 'capacity in MW',\n",
    "       'latitude', 'longitude', 'primary_fuel', 'start date', 'owner of plant',\n",
    "       'geolocation_source', 'estimated_generation_gwh_2020', 'green', 'continent', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_europe = gpd.sjoin(gdf_world.loc[gdf_world['continent'] == \"Europe\"], bb_europe, how=\"inner\", predicate='intersects').drop(\"index_right\", axis=1)\n",
    "gdf_germany = gdf_world.loc[gdf_world['country'] == \"Germany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment to serialize the data to disk\n",
    "import pickle\n",
    "pickle.dump(gdf_world, open(\"../data/gdf_world.p\", \"wb\"))\n",
    "pickle.dump(gdf_europe, open(\"../data/gdf_europe.p\", \"wb\"))\n",
    "pickle.dump(gdf_germany, open(\"../data/gdf_germany.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## alternatively save in geojson format\n",
    "gdf_world.to_file(\"../data/gdf_world.geojson\", driver='GeoJSON')\n",
    "gdf_europe.to_file(\"../data/gdf_europe.geojson\", driver='GeoJSON')\n",
    "gdf_germany.to_file(\"../data/gdf_germany.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gdf = gpd.read_file(\"file.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready!! Now it's your turn :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
