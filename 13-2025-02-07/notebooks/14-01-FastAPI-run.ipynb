{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f1b718-a8cc-43af-9a33-70a87945fd02",
   "metadata": {},
   "source": [
    "conda create --name fupy2 python==3.9 jupyterlab\n",
    "\n",
    "conda activate fupy2\n",
    "\n",
    "pip install pandas==1.3.5\n",
    "\n",
    "conda install conda-forge::fastapi\n",
    "\n",
    "conda install conda-forge::matplotlib\n",
    "\n",
    "pip install -U scikit-learn\n",
    "\n",
    "conda install conda-forge::uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-carol",
   "metadata": {},
   "source": [
    "# 1. What is an API?\n",
    "\n",
    "**API** stands for **Application Programming Interface**, it defines interactions between multiple software components.\n",
    "\n",
    "An API simplifies programming by abstracting the underlying implementation by only exposing functions a developer might actually need. \n",
    "\n",
    "It can thus also hide informations from developers.\n",
    "On one hand it can hide functions a outside developer shall have no access to, on the other hand it can hide multiple complicated functions inside one simple API call.\n",
    "\n",
    "#### *There are multiple kinds of APIs*\n",
    "\n",
    "- **Libraries**:\n",
    "    - Libraries we already got to know are basically APIs, since they abstract and simplify the underlying implementation making it really simple to use them.\n",
    "        - Examples: `pandas`, `matplotlib`, `sklearn`\n",
    "        - E.g. You can find the `sklearn` API Reference at: https://scikit-learn.org/stable/modules/classes.html\n",
    "- **Interface between programs**:\n",
    "    - An API might also act as a middleman between two programs.\n",
    "    - E.g. you want to use a library in Python which was implemented for R. An API might translate the Python commands into R to make the library run.\n",
    "- **In Operating Systems**\n",
    "    - Abstract the underlying implementation of the Operating System to make sure the outcome is generic.\n",
    "        - E.g. POSIX is an API standard utilized (mostly) by UNIX systems such as Linux, BSD, macOS\n",
    "        - It makes sure POSIX-conform API calls work the same way on each Operating System\n",
    "        - E.g. the `echo` command shall work the same way independent of the Operating System you use\n",
    "    - Backwards Compatibility:\n",
    "        - E.g. translating old system calls into those utilized in newer OS versions.\n",
    "        - Examples: Win32API (allowing old Windows Programs to be run in `Compatibility Mode` under new versions), being able to play original XBOX/Playstation games on the current Console iteration\n",
    "- **Web API**\n",
    "    - Allow to access functions through Web Protocols, such as HTTP (Hypertext Transfer Protocol)\n",
    "    - API defines endpoints (e.g. `api.twitter.com/2/users/by/username/<USERNAME>`) to fetch or push data, or even trigger code execution\n",
    "    - Responses are usually defined in `JSON` (JavaScript Object Notation) or `XML` (Extensible Markup Language) (somewhat similar to Python dictionaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-turning",
   "metadata": {},
   "source": [
    "# 2. Example: Getting to know the Twitter Web API\n",
    "\n",
    "Twitter offers an API allowing developers to easily extract and push data from/to Twitter.\n",
    "\n",
    "To get access you need to register as a developer at https://developer.twitter.com/ and apply for API acess.\n",
    "\n",
    "_Note: Not needed for this lecture as we only want to show an example of an API in the real world. You can find the data we will extract in `../data/twitter.p`._\n",
    "\n",
    "_Although we absolutely recommend to register for any API access in the wild to play around. Good alternatives to Twitter would be any major site that you are well familiar with. E.g. Google, YouTube, Spotify, Facebook_\n",
    "\n",
    "You can look up the possible API commands at https://developer.twitter.com/en/docs/twitter-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-bikini",
   "metadata": {},
   "source": [
    "### Requesting Barack Obamas Twitter Profile:\n",
    "\n",
    "You can retrieve basic information about Twitter Users using the following API endpoint: `https://api.twitter.com/2/users/by/username/<USERNAME>`\n",
    "\n",
    ">```python\n",
    ">import pandas as pd\n",
    ">import matplotlib.pyplot as plt\n",
    ">import requests\n",
    ">\n",
    "># the Twitter API endpoint\n",
    ">twitter = \"https://api.twitter.com/2/\"\n",
    "># Include your API token into the HTTP Header\n",
    ">headers = {\"Authorization\": \"Bearer <YOUR API TOKEN>\"}\n",
    "># Send a HTTP-GET Request to retrieve the user \"BarackObama\"\n",
    ">resp = requests.get(twitter + \"users/by/username/BarackObama\", headers=headers)\n",
    ">print(resp.json())\n",
    ">```\n",
    "\n",
    "#### Output\n",
    ">```python\n",
    ">{'data': {'id': '813286', 'name': 'Barack Obama', 'username': 'BarackObama'}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-freeze",
   "metadata": {},
   "source": [
    "### Requesting the Top Ten most followed Twitter users\n",
    "\n",
    "Besides the generic retrieval per user, the API also allows to pass queries for lists of users.\n",
    "`https://api.twitter.com/2/users/by?usernames=<USER1>,<USER2>,<..>`\n",
    "\n",
    "It also allows to retrieve more than the three default fields (`id, name, username`) by requesting a key value pair by adding `&key=value` at the end of the request.\n",
    "\n",
    "Examples:\n",
    "\n",
    "| key | value | returned fields |\n",
    "| --- | --- | --- |\n",
    "| `user.fields` | `created_at` | `user.created_at` |\n",
    "| `expansions` | `pinned_tweet_id` | `tweet.id`, `tweet.text` |\n",
    "| `tweet.fields` | `created_at` | `includes.users.created_at` |\n",
    "\n",
    "Thus requesting `https://api.twitter.com/2/users/by?usernames=BarackObama&user.fields=created_at&expansions=pinned_tweet_id` will additionally return the data Obamas Account has been created at and the id of his currently pinned Tweet.\n",
    "\n",
    "### Lets try it out for the top 10 most followed Twitter users:\n",
    "\n",
    ">```python\n",
    "    most_followed_users = [\n",
    "                \"BarackObama\",\n",
    "                \"justinbieber\",\n",
    "                \"katyperry\",\n",
    "                \"rihanna\",\n",
    "                \"Cristiano\",\n",
    "                \"taylorswift13\",\n",
    "                \"ladygaga\",\n",
    "                \"ArianaGrande\",\n",
    "                \"TheEllenShow\",\n",
    "                \"YouTube\"\n",
    "                ]\n",
    "    most_followed_users_str = \",\".join(most_followed_users)\n",
    "    resp = requests.get(twitter + f\"users/by?usernames={most_followed_users_string}\", headers=headers)\n",
    ">```\n",
    "\n",
    "#### Output\n",
    ">```python\n",
    "{'data': [\n",
    "      {'id': '813286',\n",
    "       'username': 'BarackObama',\n",
    "       'name': 'Barack Obama',\n",
    "       'created_at': '2007-03-05T22:08:25.000Z'}\n",
    "       ,\n",
    "      {'pinned_tweet_id': '1344890442576490496',\n",
    "       'id': '27260086',\n",
    "       'username': 'justinbieber',\n",
    "       'name': 'Justin Bieber',\n",
    "       'created_at': '2009-03-28T16:41:22.000Z'}\n",
    "       ,\n",
    "      {'pinned_tweet_id': '1299195688719249409',\n",
    "       'id': '21447363',\n",
    "       'username': 'katyperry',\n",
    "       'name': 'KATY PERRY',\n",
    "       'created_at': '2009-02-20T23:45:56.000Z'}\n",
    "       ,\n",
    "      {'id': '79293791',\n",
    "       'username': 'rihanna',\n",
    "       'name': 'Rihanna',\n",
    "       'created_at': '2009-10-02T21:37:33.000Z'}\n",
    "       ,\n",
    "      {'id': '155659213',\n",
    "       'username': 'Cristiano',\n",
    "       'name': 'Cristiano Ronaldo',\n",
    "       'created_at': '2010-06-14T19:09:20.000Z'}\n",
    "       ,\n",
    "      {'pinned_tweet_id': '1360093736932429828',\n",
    "       'id': '17919972',\n",
    "       'username': 'taylorswift13',\n",
    "       'name': 'Taylor Swift',\n",
    "       'created_at': '2008-12-06T10:10:54.000Z'}\n",
    "       ,\n",
    "      {'pinned_tweet_id': '1266218931028549632',\n",
    "       'id': '14230524',\n",
    "       'username': 'ladygaga',\n",
    "       'name': 'Lady Gaga',\n",
    "       'created_at': '2008-03-26T22:37:48.000Z'}\n",
    "       ,\n",
    "      {'pinned_tweet_id': '1322025587368742912',\n",
    "       'id': '34507480',\n",
    "       'username': 'ArianaGrande',\n",
    "       'name': 'Ariana Grande',\n",
    "       'created_at': '2009-04-23T02:56:31.000Z'}\n",
    "       ,\n",
    "      {'pinned_tweet_id': '1260696876149506048',\n",
    "       'id': '15846407',\n",
    "       'username': 'TheEllenShow',\n",
    "       'name': 'Ellen DeGeneres',\n",
    "       'created_at': '2008-08-14T03:50:42.000Z'}\n",
    "       ,\n",
    "      {'id': '10228272',\n",
    "       'username': 'YouTube',\n",
    "       'name': 'YouTube',\n",
    "       'created_at': '2007-11-13T21:43:46.000Z'}]\n",
    "       ,\n",
    "     'includes': {'tweets': [\n",
    "       {'id': '1344890442576490496',\n",
    "        'text': '#ANYONE out now\\nhttps://t.co/Uh4E6vUzZv https://t.co/UjiStYfwrz'},\n",
    "       {'id': '1299195688719249409',\n",
    "        'text': 'IT‚ÄôS HERE! IT‚ÄôS REALLY HERE! üôÉ I finally got back my smile! Hope this record puts one on your face üôÇ #SMILE üôÇ IS OUT EVERYWHERE NOW! LOVE YOU GUYS SO MUCH ENJOY ü§°‚ô•Ô∏è (sent from my hospital bed lol) https://t.co/BImXF3kEcw https://t.co/2UmVajDoyn'},\n",
    "       {'id': '1360093736932429828',\n",
    "        'text': 'My new version of Love Story (Taylor‚Äôs Version) is out now  üíõüíõ Get it instantly when you pre-order Fearless (Taylor‚Äôs Version)  https://t.co/NqBDS6cGFl https://t.co/KdHdZXnWbP'},\n",
    "       {'id': '1266218931028549632',\n",
    "        'text': 'Now dance motherfüíïckers!!!!!!! #Chromatica https://t.co/GjJUC3PRWz'},\n",
    "       {'id': '1322025587368742912',\n",
    "        'text': 'ü§ç positions (the album) is out now ü§ç https://t.co/FpkiHYLFqt https://t.co/J33o6KMTmo'}]},\n",
    "     'errors': [\n",
    "       {'detail': 'Could not find tweet with pinned_tweet_id: [1260696876149506048].',\n",
    "       'title': 'Not Found Error',\n",
    "       'resource_type': 'tweet',\n",
    "       'parameter': 'pinned_tweet_id',\n",
    "       'value': '1260696876149506048',\n",
    "       'type': 'https://api.twitter.com/2/problems/resource-not-found'}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-appearance",
   "metadata": {},
   "source": [
    "# 3. Analyzing the data\n",
    "\n",
    "We extracted for you the user- and most recent tweet- (last 7 days) data. For both we only used the `created_at` and `public_metrics` queries. \n",
    "\n",
    ">```python\n",
    "tweet_dict = {}\n",
    "for user in most_followed_users:\n",
    "    resp = requests.get(twitter + f\"tweets/search/recent?query=from:{user}&tweet.fields=public_metrics,created_at\", headers=headers, proxies=proxies)\n",
    "    tweet_dict[user] = resp.json()\n",
    ">```\n",
    "\n",
    ">```python\n",
    "user_dict = {}\n",
    "for user in most_followed_users:\n",
    "    resp = requests.get(twitter + f\"users/by?usernames={user}&user.fields=public_metrics,created_at\", headers=headers, proxies=proxies)\n",
    "    user_dict[user] = resp.json()\n",
    ">```\n",
    "\n",
    ">```python\n",
    "># this is the data made available to you\n",
    "twitter_data = {\n",
    "    'user_info': user_dict,\n",
    "    'tweets': tweet_dict\n",
    "}\n",
    ">```\n",
    "\n",
    "Lets see how much we can find out about their Twitter behavior just from requesting these two keys through the API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load default libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# load the data\n",
    "twitter_data = pickle.load( open( \"../data/twitter.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-offense",
   "metadata": {},
   "source": [
    "## 3.1 Inspect the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['user_info'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['user_info']['BarackObama'].keys()\n",
    "twitter_data['user_info']['BarackObama']['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-scheme",
   "metadata": {},
   "source": [
    "The dictionary consists of two parts:\n",
    "- `user_info` containing the metadata (num followers, etc.) of each of the top ten users\n",
    "- `tweets` containing tweets of the corresponding users and its metadata (num likes, etc.)\n",
    "\n",
    "Each subdictionary contains for each user key a list of dictionaries hidden behind the `data` key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-needle",
   "metadata": {},
   "source": [
    "## 3.2 Building a DataFrame\n",
    "\n",
    "To better access individual values we want to turn the dictionary into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['user_info'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for user in twitter_data['user_info'].keys():\n",
    "    # user data\n",
    "    data = twitter_data['user_info'][user]['data'][0]\n",
    "    # public metrics is a dictionary inside user data\n",
    "    # with dict.pop(key) we can remove a key from a dictionary\n",
    "    # with dict.update(other_dict) we can merge two dictionaries together\n",
    "    data.update(data.pop('public_metrics'))\n",
    "    # when adding a row from a dictionary into a pandas DataFrame you need to pass 'ignore_index=True'\n",
    "    # Note: pd.DataFrame.append() doesn't work inplace like the list.append()! \n",
    "    # Thus we need to overwrite our DataFrame with the appended one\n",
    "    df = df.append(data, ignore_index = True)    \n",
    "                \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to a meaningful unique identifier\n",
    "df = df.set_index('username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-transsexual",
   "metadata": {},
   "source": [
    "## 3.3 Analyze Tweets\n",
    "\n",
    "We got the user metadata into a DataFrame, but we're still left with the tweets part of the dictionary untouched.\n",
    "Lets do something with it ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-timber",
   "metadata": {},
   "source": [
    "The tweet subdictionary contains all(*) Tweets a user has posted in the last 7 days (Fetched at 18.02.2021).\n",
    "\n",
    "(*) _Note: Twitter only allows to fetch 100 Tweets at once. Which is why the number of Tweets the \"YouTube\" Account has posted is incorrect_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-campus",
   "metadata": {},
   "source": [
    "### 3.3.1. Number of Tweets posted\n",
    "\n",
    "> **Task:** Insert the number of Tweets posted by each user in the last 7 days into our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/number_of_tweets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-commercial",
   "metadata": {},
   "source": [
    "### 3.3.2 Most likes on a tweet\n",
    "> **Task:** Insert the number of most liked Tweets each user in the last 7 days into our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/max_number_of_tweets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-parent",
   "metadata": {},
   "source": [
    "At this point we should notice a pattern in the way our code finds out the maximum value for some kind of metric (keyword: code refactoring).\n",
    "> **Task:** Define a function which does the following:    \n",
    "> **INPUT**: metric, function (min, max, std, ...)  \n",
    "> **OUTPUT**: dictionary where for each user the function was applied to all values related to the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/tweets_metric_func.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-application",
   "metadata": {},
   "source": [
    "Now, using the function, we can easily calculate the minimum/maximum/... values with respect to a metric. Try it out!\n",
    "\n",
    "> **Task:**  \n",
    "> - Insert for each user the maximum number of replys on a Tweet into our DataFrame.  \n",
    "> - Insert for each user the maximum number of retweets on a Tweet into our DataFrame. \n",
    "> - Insert for each user the minimal number of like_count on a Tweet into our DataFrame.  \n",
    "> - Insert for each user the avarage number of likes on a Tweet into our Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/metric_tests.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-general",
   "metadata": {},
   "source": [
    "## 3.4 Analyze DataFrame\n",
    "\n",
    "Now let's look at our built DataFrame and read the minimum or maximum values from a column.\n",
    "\n",
    "> **Task:**  \n",
    "> **Q1)** Who tweeted the most in the last 7 days?  \n",
    "> **Q2)** Who has the most likes on a tweet?  \n",
    "> **Q3)** Who has the most retweets on a tweet?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/max_tweeted.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/max_likes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/max_retweets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-courtesy",
   "metadata": {},
   "source": [
    "> **Task**: Compute the daily mean of posted tweets since the creation of the account for a single user.\n",
    "\n",
    "> _Hint: You can use `pd.datetime.now()` to retrieve the current date. The columns of interest are: `created_at` and `tweet_count`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at']).dt.tz_convert(tz=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/_solutions/daily_mean_posted_tweets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-western",
   "metadata": {},
   "source": [
    "# 4. Building our own API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-bernard",
   "metadata": {},
   "source": [
    "## FastAPI\n",
    "\n",
    "FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints.\n",
    "\n",
    "- Fast: Very high performance, on par with NodeJS and Go (thanks to Starlette and Pydantic). One of the fastest Python frameworks available.\n",
    "- Fast to code: Increase the speed to develop features by about 200% to 300%. *\n",
    "- Fewer bugs: Reduce about 40% of human (developer) induced errors. *\n",
    "- Intuitive: Great editor support. Completion everywhere. Less time debugging.\n",
    "- Easy: Designed to be easy to use and learn. Less time reading docs.\n",
    "- Short: Minimize code duplication. Multiple features from each parameter declaration. Fewer bugs.\n",
    "- Robust: Get production-ready code. With automatic interactive documentation.\n",
    "- Standards-based: Based on (and fully compatible with) the open standards for APIs: OpenAPI (previously known as Swagger) and JSON Schema.\n",
    "\n",
    "Source: https://fastapi.tiangolo.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-chester",
   "metadata": {},
   "source": [
    "### **Very simple example of an Web-API**\n",
    "\n",
    "#### **Underlying implementation**\n",
    "The underlying implementation consists of seperated functions.\n",
    "```python\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "xs, y, valid_xs, valid_y = train_test_split(dataset)\n",
    "\n",
    "def fit_model(model, xs, y):\n",
    "    return model.fit(xs,y)\n",
    "\n",
    "def predict(trained_model, xs):\n",
    "    return trained_model.predict(xs)\n",
    "\n",
    "def eval_prediction(y_orig, y_predicted):\n",
    "    return sklearn.metrics.mean_squared_error(y_orig, y_predicted)\n",
    "\n",
    "def something_secret():\n",
    "    # do secret stuff\n",
    "```\n",
    "\n",
    "#### **API**\n",
    "The Web-API allows by accessing a website at `/train_and_eval` to chain all of the above functions together to train and evaluate a model.\n",
    "\n",
    "It doesn't expose the `something_secret()` function to the outside world though!\n",
    "\n",
    "```python\n",
    "@api.get(\"/train_and_eval\")\n",
    "def train_and_eval():\n",
    "    model_trained = fit_model(xs, y)\n",
    "    valid_y_pred = predict(model_trained, valid_xs)\n",
    "    rmse = eval_prediction(valid_y, valid_y_pred)\n",
    "    \n",
    "    return {\"rmse\": rmse, \"model_params\": model_trained.get_params()}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-monday",
   "metadata": {},
   "source": [
    "## Lets try it out!\n",
    "\n",
    "We have implemented a very rudimentary API, which you can find in `../src/api_01.py`.\n",
    "The only thing it does is returning \"Hello World\" when accessing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/api_01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-greene",
   "metadata": {},
   "source": [
    "You can launch it the following way:\n",
    "- Open your Terminal (Linux, macOS) or Anaconda Prompt (Windows)\n",
    "- Activate class14 in `conda`\n",
    "- Head over to the `src` directory of todays lesson (use `cd`, `ls` and `pwd` to orientate yourself)\n",
    "- Run `uvicorn api_01:app --debug`\n",
    "\n",
    "- _Further Info_\n",
    "    - `uvicorn` is a  minimal low-level server/application interface allowing asynchronous executions\n",
    "    - Similarly to `jupyter lab` it hosts some kind of website on our host\n",
    "    - Syntax: `uvicorn <python file>:<variable or function to run>`\n",
    "    - The `--debug` flag makes sure the server restarts each time we change the source file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-milwaukee",
   "metadata": {},
   "source": [
    ">After starting the server head over to https://127.0.0.1:8000/.\n",
    ">You should see the \"Hello World\" message\n",
    "\n",
    ">_Note: `127.0.0.1` is the same as `localhost` which is the IP-Address/Hostname of your own PC_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-worthy",
   "metadata": {},
   "source": [
    "FastAPI also offers a Docpage at http://127.0.0.1:8000/docs which:\n",
    "- Shows you all available API commands\n",
    "- Allows you to experiment with them\n",
    "- Prints you the `curl` command you should use from the terminal to receive the same result as in the browser\n",
    "    - _Note: We limit ourselves to the HTTP-GET Method, which is used to retrieve data. (Your browser does per default) If we wanted to send something to the server we should use the HTTP-POST Method, which is easier to do with `curl` than manually through your browser._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-queue",
   "metadata": {},
   "source": [
    "## Try something a bit more complex\n",
    "\n",
    ">**Goal**: Make a model accessible through an API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-relative",
   "metadata": {},
   "source": [
    "### The Iris Dataset\n",
    "\n",
    "The Iris Dataset is one of the most well known Classification datasets.\n",
    "Based on the length and width of the sepal and petal we want to classify iris flowers correctly.\n",
    "\n",
    "![_img/iris.png](_img/iris.png)\n",
    "Taken from [Machine Learning for Beginners](https://www.datacamp.com/community/tutorials/machine-learning-in-r)\n",
    "\n",
    "The sepal is the small/lower blossom, petal the upper/main blossom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-melbourne",
   "metadata": {},
   "source": [
    "Lets train a Random Forest Classifier to classify our data.\n",
    "\n",
    "Reminder: Random Forests consist of multiple Decision Trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_jobs = -1 allows to use all our available computing power\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Random Forest\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance\n",
    "accuracy_score(y_test, rf.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-coordination",
   "metadata": {},
   "source": [
    ">We have already implemented this into an API, so don't worry. You can launch it by again going into the `src` directory and executing `uvicorn api_02:app --debug`. \n",
    "\n",
    ">Play around with it and feel free to add some extra functionality (doesn't necessarily have something to do with the model. Be creative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
